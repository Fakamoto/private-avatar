#######################
# IMPORTS
#######################
import json
import asyncio
from typing import List, Optional
import os
import tempfile
import shutil # Import shutil for rmtree
from fastapi import BackgroundTasks, Depends, HTTPException, APIRouter
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
from sqlmodel import Session, select, delete
from sqlalchemy.orm import selectinload
import urllib
import re # Add import re

from backend.database import (
    Course,
    CourseRead,
    Document,
    Lesson,
    LessonRead,
    Section,
    Slide,
    engine,
    get_session,
    Quiz,
)

from backend.ai import (
    genererate_course_plan,
    improve_lesson,
    write_lesson,
    generate_time_structure,
    get_lesson_plan_with_retry,
    write_presentation_markdown,
    improve_slides,
    create_quiz,
)

from backend.utils import (
    LessonTimeStructure,
    # sanitize_latex,
)

# Import AI image helper to replace placeholders with real generated images
from backend.endpoints.slides import generate_ai_images_for_markdown

import logging

# Import the library for PDF generation
import pypandoc

#######################
# LOGGING SETUP
#######################
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
)
logger = logging.getLogger("app")

#######################
# ROUTER INSTANCE
#######################
router = APIRouter()

#######################
# MODELS
#######################

class CreateCourseRequest(BaseModel):
    name: str


class GenerateCoursePlanRequest(BaseModel):
    prompt: str
    language: str
    duration_minutes: int = Field(ge=5)
    ai_images: bool = False

class UpdateCourseRequest(BaseModel):
    title: str


class UpdateSectionRequest(BaseModel):
    title: Optional[str] = None
    content: Optional[str] = None
    short_description: Optional[str] = None
    duration_minutes: Optional[int] = None
    instructions: Optional[str] = None
    style: Optional[str] = None

class GenerateFullCourseRequest(BaseModel):
    prompt: str
    language: str
    duration_minutes: int = Field(ge=5)
    ai_images: bool = False

class IsWorkingResponse(BaseModel):
    is_working: bool

class CourseMarkdownResponse(BaseModel):
    markdown_content: str

#######################
# AI ENDPOINTS
#######################

@router.get("/courses/{course_id}/is-working", response_model=IsWorkingResponse, tags=["Courses"])
async def is_course_working_endpoint(
    course_id: int, session: Session = Depends(get_session)
):
    """Check if the course is working on a task"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")
    return IsWorkingResponse(is_working=course.is_working)


@router.post("/courses", response_model=CourseRead, tags=["Courses"])
async def create_course_endpoint(
    request: CreateCourseRequest, session: Session = Depends(get_session)
):
    """Creates a course with just a name"""
    db_course = Course(name=request.name)
    session.add(db_course)
    session.commit()
    session.refresh(db_course)

    return db_course

@router.post("/courses/{course_id}/plan", response_model=CourseRead, tags=["Courses"])
async def generate_course_plan_endpoint(
    course_id: int,
    request: GenerateCoursePlanRequest,
    background_tasks: BackgroundTasks,
    session: Session = Depends(get_session),
):
    """Generates the course plan using uploaded documents as context-- a prompt and title for each lesson"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")

    if course.lessons:
        for lesson in course.lessons:
            session.delete(lesson)
        session.commit()
        session.refresh(course)

    background_tasks.add_task(
        run_course_plan_task,
        course_id=course_id,
        request=request
    )

    course.prompt = request.prompt
    course.language = request.language
    course.duration_minutes = request.duration_minutes
    course.ai_images = request.ai_images
    session.add(course)
    session.commit()
    session.refresh(course)

    return course

@router.post("/courses/{course_id}/lessons/plan", response_model=CourseRead, tags=["Courses"])
async def generate_course_lessons_plan_endpoint(
    course_id: int,
    background_tasks: BackgroundTasks,
    session: Session = Depends(get_session),
):
    """Generate lesson plans with sections for all lessons in a course following prompts generated by generate_course_plan_endpoint /courses/{course_id}/plan endpoint"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")

    if not course.lessons:
        raise HTTPException(
            status_code=400,
            detail="Course has no lessons. Generate a course plan first using the /courses/{course_id}/plan endpoint",
        )

    background_tasks.add_task(
        run_lessons_plan_task,
        course_id=course_id
    )

    return course

@router.post("/courses/{course_id}/lessons/write", response_model=CourseRead, tags=["Courses"])
async def write_course_lessons_endpoint(
    course_id: int,
    background_tasks: BackgroundTasks,
    session: Session = Depends(get_session)
):
    """Write and improve content for all sections in all lessons of a course"""
    logger.info(f"[API] Received request to write content for all lessons in course ID: {course_id}")
    
    course = session.get(Course, course_id)
    if not course:
        logger.warning(f"[API] ERROR: Course ID {course_id} not found")
        raise HTTPException(status_code=404, detail="Course not found")

    if not course.lessons:
        logger.warning(f"[API] ERROR: Course ID {course_id} has no lessons")
        raise HTTPException(
            status_code=400,
            detail="Course has no lessons. Generate a course plan first using the /courses/{course_id}/plan endpoint",
        )

    background_tasks.add_task(
        run_write_lessons_task,
        course_id=course_id
    )

    return course


#######################
# CRUD ENDPOINTS
#######################

@router.get("/courses", response_model=List[CourseRead], tags=["Courses"])
async def list_courses_endpoint(
    session: Session = Depends(get_session), skip: int = 0, limit: int = 100
):
    """List all courses with pagination"""
    courses = session.exec(select(Course).offset(skip).limit(limit)).all()
    return courses

@router.get("/courses/{course_id}", response_model=CourseRead, tags=["Courses"])
async def get_course_endpoint(course_id: int, session: Session = Depends(get_session)):
    """Get a specific course by ID"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")
    return course

@router.delete("/courses/{course_id}", tags=["Courses"])
async def delete_course_endpoint(
    course_id: int, session: Session = Depends(get_session)
):
    """Delete a course and all its related data"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")
    session.delete(course)
    session.commit()
    return {"ok": True}

@router.get("/courses/{course_id}/lessons", response_model=List[LessonRead], tags=["Lessons"])
async def list_course_lessons_endpoint(
    course_id: int, session: Session = Depends(get_session)
):
    """List all lessons for a specific course"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")
    return course.lessons

@router.put("/courses/{course_id}", response_model=CourseRead, tags=["Courses"])
async def update_course_endpoint(
    course_id: int,
    request: UpdateCourseRequest,
    session: Session = Depends(get_session),
):
    """Update a course's title"""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")

    course.title = request.title
    session.add(course)
    session.commit()
    session.refresh(course)
    return course

@router.get("/courses/{course_id}/markdown", response_model=CourseMarkdownResponse, tags=["Courses"])
async def get_course_markdown_endpoint(course_id: int, session: Session = Depends(get_session)):
    """Get all section content for a course as a single Markdown string."""
    course = session.get(Course, course_id)
    if not course:
        raise HTTPException(status_code=404, detail="Course not found")

    lessons = session.exec(
        select(Lesson)
        .where(Lesson.course_id == course_id)
        .options(selectinload(Lesson.sections))
        .order_by(Lesson.id)
    ).all()

    if not lessons:
        return CourseMarkdownResponse(markdown_content="")

    markdown_parts = []
    for lesson in lessons:
        sorted_sections = sorted(lesson.sections, key=lambda s: s.id)
        for section in sorted_sections:
            if section.title and section.content:
                markdown_parts.append(f"## {section.title}\n\n")
                markdown_parts.append(f"{section.content}\n\n")
            elif section.content:
                markdown_parts.append(f"{section.content}\n\n")

    full_markdown = "".join(markdown_parts).strip()

    return CourseMarkdownResponse(markdown_content=full_markdown)

@router.post("/courses/{course_id}/generate-full", response_model=CourseRead, tags=["Courses"])
async def generate_full_course_endpoint(
    course_id: int,
    request: GenerateFullCourseRequest,
    background_tasks: BackgroundTasks,
    session: Session = Depends(get_session),
):
    """
    Triggers the full generation pipeline for a course:
    Plan -> Lessons Plan -> Write Lessons -> Improve Lessons -> Generate Presentation Slides.
    """
    logger.info(f"[API][generate_full_course_endpoint] Received request for course ID: {course_id}")
    course = session.get(Course, course_id)
    if not course:
        logger.warning(f"[API][generate_full_course_endpoint] Course {course_id} not found.")
        raise HTTPException(status_code=404, detail="Course not found")

    course.prompt = request.prompt
    course.language = request.language
    course.duration_minutes = request.duration_minutes
    course.ai_images = request.ai_images
    session.add(course)
    session.commit()

    background_tasks.add_task(
        run_full_course_generation_task,
        course_id=course_id,
        request_data=request.model_dump()
    )

    return course

@router.get("/courses/{course_id}/pdf", response_class=FileResponse, tags=["Courses"])
async def download_course_pdf_endpoint(course_id: int, background_tasks: BackgroundTasks, session: Session = Depends(get_session)):
    """Generate and download the full course content as a PDF file"""
    logger.info(f"Received request to download PDF for course ID: {course_id}")

    # Fetch the course with lessons and sections preloaded
    course = session.exec(
        select(Course)
        .where(Course.id == course_id)
        .options(
            selectinload(Course.lessons)
            .selectinload(Lesson.sections)
        )
    ).first()

    if not course:
        logger.warning(f"Course ID {course_id} not found for PDF generation.")
        raise HTTPException(status_code=404, detail="Course not found")

    logger.info(f"Course '{course.name}' found. Generating Markdown content.")

    # Prepare Markdown content using the helper function
    markdown_content = get_course_markdown_content(course)
    # Remove lines consisting only of 3 or more hyphens, asterisks, or underscores
    markdown_content = re.sub(r"^[-*_]{3,}$", "", markdown_content, flags=re.MULTILINE).strip()
    logger.info("Removed horizontal rule lines (---, ***, ___, etc.) from markdown.")
    # markdown_content = sanitize_latex(markdown_content)
    markdown_content = markdown_content.replace('\\$', '$')
    assert '\\$' not in markdown_content, "escaped dollar still present"
    logger.info(f"NO ESCAPED DOLLARS")
    logger.info("Markdown content generated. Preparing for PDF conversion using pypandoc.")

    # Create a temporary directory manually
    temp_dir = tempfile.mkdtemp()
    logger.info(f"Created temporary directory: {temp_dir}")

    try:
        safe_course_name = "".join(
            c if c.isalnum() or c in (" ", "-") else "_" for c in course.name
        ).rstrip().replace(" ", "_")
        pdf_filename = f"{safe_course_name}_course_{course_id}.pdf"
        output_pdf_path = os.path.join(temp_dir, pdf_filename)

        # Use pypandoc to convert Markdown to PDF
        logger.info(f"Converting Markdown to PDF at path: {output_pdf_path} using minted for highlighting.")
        pandoc_args = [
            # Basic Setup & Engine
            '--pdf-engine=xelatex',
            # Tell LaTeX engine to allow calling external programs (needed for minted)
            '--pdf-engine-opt=-shell-escape',
            # Remove Pandoc's internal highlighting to potentially trigger minted
            # '--highlight-style=pygments', 
            '-t', 'pdf',
            # Font Configuration (use fonts with good Unicode coverage)
            '-V', 'mainfont=DejaVu Sans',        # Main text font
            '-V', 'sansfont=DejaVu Sans',        # Sans-serif font
            '-V', 'monofont=DejaVu Sans Mono',   # Code/monospace font
            '-V', 'mathfont=DejaVu Math TeX Gyre',
            # Basic Styling
            '-V', 'geometry:margin=1in',
            '-V', 'fontsize=11pt',
            # LaTeX Preamble Additions (Load amsmath for better math, dvipsnames for minted colors)
            '-V', 'header-includes=\\usepackage{amsmath}\\usepackage{graphicx}\\usepackage{xcolor}',
            '-V', 'classoption=dvipsnames' # Often needed for minted color definitions
            # Optionally add '-V colorlinks' for colored hyperlinks
            # '-V', 'colorlinks'
        ]

        pypandoc.convert_text(
            markdown_content,
            'pdf',
            format='markdown-yaml_metadata_block', # Keep YAML parsing disabled
            outputfile=output_pdf_path,
            extra_args=pandoc_args
        )
        logger.info(f"PDF successfully generated: {output_pdf_path}")

        # Add background task to clean up the temporary directory after response is sent
        background_tasks.add_task(cleanup_temp_dir, temp_dir)
        logger.info(f"Scheduled cleanup task for directory: {temp_dir}")


        # Return the generated PDF file
        download_filename = urllib.parse.quote(f"{course.name}.pdf")
        return FileResponse(
            path=output_pdf_path,
            filename=download_filename,
            media_type='application/pdf'
            # No background argument needed here
        )

    except FileNotFoundError as e:
        logger.error(f"Pandoc Error for course {course_id}: Pandoc executable not found or PATH issue. Error: {e}", exc_info=True)
        background_tasks.add_task(cleanup_temp_dir, temp_dir) # Ensure cleanup even on Pandoc path error
        raise HTTPException(status_code=500, detail="PDF Generation Error: Pandoc executable not found. Check server configuration.")
    except OSError as e:
        logger.error(f"Pandoc/OS Error for course {course_id}: Conversion failed. May be due to Pandoc, LaTeX, or markdown issues. Error: {e}", exc_info=True)
        background_tasks.add_task(cleanup_temp_dir, temp_dir) # Ensure cleanup even on conversion error
        raise HTTPException(status_code=500, detail=f"PDF Generation Error: Conversion failed. Check server logs. Error: {e}")
    except Exception as e:
        logger.error(f"Error during PDF generation process for course {course_id}: {e}", exc_info=True)
        # Ensure cleanup task is added even if other exceptions occur before returning FileResponse
        background_tasks.add_task(cleanup_temp_dir, temp_dir)
        raise HTTPException(status_code=500, detail=f"Failed to generate PDF: {e}")

# Helper function for cleanup
def cleanup_temp_dir(temp_dir_path: str):
    try:
        logger.info(f"Cleaning up temporary directory: {temp_dir_path}")
        shutil.rmtree(temp_dir_path)
        logger.info(f"Successfully removed temporary directory: {temp_dir_path}")
    except Exception as e:
        logger.error(f"Error cleaning up temporary directory {temp_dir_path}: {e}", exc_info=True)


# Helper function to generate markdown content (extracted from the endpoint)
def get_course_markdown_content(course: Course) -> str:
    """Generates the full Markdown content for a given course, optimized for PDF export."""
    # --- YAML Metadata Block ---
    metadata_lines = [
        "---",
        f"title: {course.name}",
    ]
    if course.language:
        metadata_lines.append(f"lang: {course.language}")
    if course.duration_minutes:
        metadata_lines.append(f"duration: {course.duration_minutes} minutes")
    # Add other relevant metadata if needed (e.g., author, date)
    # metadata_lines.append(f"author: Your Name") 
    metadata_lines.append("---")
    metadata_block = "\n".join(metadata_lines) + "\n\n"

    # --- Course Content ---
    content_parts = []

    sorted_lessons = sorted(course.lessons, key=lambda l: l.id)
    for lesson_num, lesson in enumerate(sorted_lessons, start=1):
        # Add page break before each lesson
        if lesson_num > 1:
            content_parts.append("\newpage\n") 

        content_parts.append(f"## Lesson {lesson_num}: {lesson.title}\n\n")
        if lesson.prompt:
            # Optional: Include lesson prompt, perhaps styled differently or commented out for PDF
            # content_parts.append(f"> **Lesson Prompt:** {lesson.prompt}\n\n") 
            pass # Keep prompts out of the main PDF content for now

        sorted_sections = sorted(lesson.sections, key=lambda s: s.id)
        for section_num, section in enumerate(sorted_sections, start=1):
            content_parts.append(f"### Section {section_num}: {section.title}\n\n")
            if section.content:
                # Ensure content ends with exactly two newlines before the next heading
                content_parts.append(section.content.strip() + "\n\n") 
            else:
                content_parts.append("*Note: No content was generated for this section.*\n\n")

    # Combine metadata and content
    full_markdown = metadata_block + "".join(content_parts).strip()

    return full_markdown


def run_course_plan_task(course_id: int, request: GenerateCoursePlanRequest):
    """Background task to generate the course plan"""
    logger.info(f"[BACKGROUND][run_course_plan_task][{course_id}] Starting for course ID: {course_id}")
    logger.debug(f"[BACKGROUND][run_course_plan_task][{course_id}] Request data: {request}")

    async def _actual_course_plan_task():
        """Asynchronous core logic for course plan generation."""
        logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Entering async core logic.")
        course = None
        with Session(engine) as session:
            try:
                course = session.get(Course, course_id)
                if not course:
                    logger.error(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course {course_id} not found in DB.")
                    return
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course {course_id} fetched.")
                course.is_working = True
                session.add(course)
                session.commit()
                session.refresh(course)
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Set is_working=True for course {course_id}.")


                if course.lessons:
                    num_lessons_to_delete = len(course.lessons)
                    logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Deleting {num_lessons_to_delete} existing lessons for course {course_id}.")
                    for i, lesson in enumerate(course.lessons):
                        logger.debug(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Deleting lesson {i+1}/{num_lessons_to_delete} (ID: {lesson.id}).")
                        session.delete(lesson)
                    session.commit()
                    session.refresh(course)
                    logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Finished deleting existing lessons.")
                else:
                     logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] No existing lessons to delete for course {course_id}.")

                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Analyzing documents and fetching relevant content.")
                relevant_content = course.get_relevant_content(request.prompt)
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Fetched {len(relevant_content) if relevant_content else 0} relevant content chunks.")

                # ----- Start Asynchronous AI Calls ----- #
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Starting async AI call for time structure.")
                time_structure = await generate_time_structure(request.prompt, request.duration_minutes, retry=3)
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Async time structure generation completed. Result: {time_structure}")

                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Starting async AI call for course plan.")
                course_plan = await genererate_course_plan(
                     request.prompt, request.language, time_structure, relevant_content
                )
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Async course plan generation completed.")
                logger.debug(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Generated course plan details: {course_plan}")
                # ----- End Asynchronous AI Calls ----- #

                # ----- Start Synchronous DB Updates ----- #
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Starting synchronous DB updates.")
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Refreshing and updating course {course_id} metadata.")
                session.refresh(course)
                course.preset = course_plan.slide_preset
                course.background = "light"
                course.title = course_plan.title_for_course
                course.prompt = request.prompt
                course.language = request.language
                course.number_of_lessons = time_structure.number_of_lessons
                course.time_structure = json.dumps(time_structure.model_dump())
                course.duration_minutes = time_structure.duration_minutes
                course.ai_images = request.ai_images
                session.add(course)
                session.commit()
                session.refresh(course)
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course {course_id} metadata updated and committed.")

                num_lessons_to_create = time_structure.number_of_lessons
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Creating {num_lessons_to_create} new lessons.")

                for i in range(num_lessons_to_create):
                    logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Creating lesson {i+1}/{num_lessons_to_create}.")
                    lesson = Lesson(
                        title=course_plan.title_for_lesson[i],
                        prompt=course_plan.prompt_for_lesson[i],
                        course_id=course.id,
                        time_structure=json.dumps(time_structure.lessons[i].model_dump()),
                        duration_minutes=time_structure.lessons[i].duration_minutes
                    )
                    session.add(lesson)
                    logger.debug(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Lesson {i+1} added to session (Title: {lesson.title}).")

                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Committing all {num_lessons_to_create} new lessons.")
                session.commit()
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] New lessons committed.")

                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course plan task completed successfully for course ID: {course_id}")
                # ----- End Synchronous DB Updates ----- #

            except Exception as e:
                logger.exception(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Error during execution for course {course_id}: {e}")

            finally:
                logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Entering finally block.")
                if course and session.is_active:
                    logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Setting is_working=False for course {course_id}.")
                    try:
                        course_in_session = session.get(Course, course_id)
                        if course_in_session:
                            course_in_session.is_working = False
                            session.add(course_in_session)
                            session.commit()
                            logger.info(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Committed is_working=False.")
                        else:
                            logger.warning(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course {course_id} not found in session during finally block.")
                    except Exception as finally_e:
                        logger.error(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Error setting is_working=False in finally block: {finally_e}")
                        session.rollback()
                elif not course:
                    logger.warning(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Course object was None in finally block, cannot set is_working=False.")
                elif not session.is_active:
                    logger.warning(f"[BACKGROUND][_actual_course_plan_task][{course_id}] Session inactive in finally block, cannot set is_working=False.")
    try:
        logger.info(f"[BACKGROUND][run_course_plan_task][{course_id}] Running async core logic using asyncio.run().")
        asyncio.run(_actual_course_plan_task())
        logger.info(f"[BACKGROUND][run_course_plan_task][{course_id}] Async core logic finished.")
    except Exception as e:
        logger.error(f"[BACKGROUND][run_course_plan_task][{course_id}] Top-level error running task for {course_id}: {e}", exc_info=True)
    finally:
        logger.info(f"[BACKGROUND][run_course_plan_task][{course_id}] Background task execution finished for course {course_id}.")

def run_lessons_plan_task(course_id: int):
    """Background task wrapper to generate lesson plans for a course asynchronously."""
    logger.info(f"[BACKGROUND][run_lessons_plan_task][{course_id}] Starting for course ID: {course_id}")

    async def _actual_lessons_plan_task():
        """Asynchronous core logic for generating lesson plans."""
        logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Entering async core logic.")
        course = None
        with Session(engine) as session:
            try:
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Fetching course data.")
                course = session.get(Course, course_id)
                if not course:
                    logger.error(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Course {course_id} not found.")
                    return
                if not course.lessons:
                    logger.error(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Course {course_id} has no lessons.")
                    return

                course.is_working = True
                session.add(course)
                session.commit()
                session.refresh(course)
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Set is_working=True for course {course_id} (with {len(course.lessons)} lessons)." )

                language = course.language

                lessons_to_process = []
                num_lessons_total = len(course.lessons)
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Preparing data for {num_lessons_total} lessons.")
                for i, lesson in enumerate(course.lessons):
                    logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Preparing lesson {i+1}/{num_lessons_total} (ID: {lesson.id}).")
                    if lesson.sections:
                        num_sections_to_delete = len(lesson.sections)
                        logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Deleting {num_sections_to_delete} existing sections for lesson {lesson.id}.")
                        for j, section in enumerate(lesson.sections):
                            logger.debug(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Deleting section {j+1}/{num_sections_to_delete} (ID: {section.id}) for lesson {lesson.id}.")
                            session.delete(section)
                        session.commit()
                        session.refresh(lesson)
                        logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Finished deleting existing sections for lesson {lesson.id}.")
                    else:
                         logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] No existing sections to delete for lesson {lesson.id}.")

                    try:
                        lesson_time_structure = LessonTimeStructure.model_validate_json(lesson.time_structure)
                        logger.debug(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Validated time structure for lesson {lesson.id}: {lesson_time_structure}")
                    except Exception as time_err:
                        logger.error(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Invalid time structure for lesson {lesson.id}: {time_err}. Skipping lesson.")
                        continue

                    logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Fetching relevant content for lesson {lesson.id}.")
                    relevant_content = course.get_relevant_content(lesson.prompt)
                    logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Fetched {len(relevant_content) if relevant_content else 0} relevant chunks for lesson {lesson.id}.")
                    lessons_to_process.append((lesson.id, lesson.prompt, lesson_time_structure, relevant_content))
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Finished preparing data. {len(lessons_to_process)} lessons are ready for AI processing.")

                # ----- Start Asynchronous AI Calls ----- #
                num_ai_tasks = len(lessons_to_process)
                if num_ai_tasks == 0:
                    logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] No valid lessons to process after preparation. Completing task.")
                    return

                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Starting async AI calls for {num_ai_tasks} lesson plans.")
                ai_tasks = []
                for lesson_id, prompt, time_struct, rel_content in lessons_to_process:
                    logger.debug(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Creating AI task for lesson {lesson_id}.")
                    ai_tasks.append(get_lesson_plan_with_retry(prompt, language, time_struct, rel_content))

                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Gathering results from {len(ai_tasks)} AI lesson plan generation tasks.")

                structured_plans_results = await asyncio.gather(*ai_tasks, return_exceptions=True)
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Finished gathering AI results for {len(structured_plans_results)} lessons.")
                # ----- End Asynchronous AI Calls ----- #

                # ----- Start Synchronous DB Updates ----- #
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Starting synchronous DB updates for generated plans.")
                processed_lessons_count = 0

                for i, result in enumerate(structured_plans_results):
                    lesson_id, _, _, _ = lessons_to_process[i]
                    lesson = session.get(Lesson, lesson_id)
                    if not lesson:
                        logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Lesson {lesson_id} not found during result processing. Skipping.")
                        continue

                    if isinstance(result, Exception):
                        logger.error(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Failed to generate plan for lesson {lesson_id}: {result}")
                        continue
                    elif result:
                        structured_plan = result
                        num_sections_generated = len(structured_plan.sections)
                        logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Successfully generated plan for lesson {lesson_id} with {num_sections_generated} sections.")
                        logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Updating general plan and creating {num_sections_generated} sections for lesson {lesson.id}.")
                        lesson.general_plan = structured_plan.general_plan
                        session.add(lesson)
                        for j, section_plan in enumerate(structured_plan.sections):
                            logger.debug(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Creating section {j+1}/{num_sections_generated} for lesson {lesson.id}.")
                            section = Section(
                                short_description=section_plan.short_description,
                                instructions=section_plan.instructions,
                                style=section_plan.style,
                                duration_minutes=section_plan.duration_minutes,
                                lesson_id=lesson.id
                            )
                            session.add(section)
                        session.commit()
                        processed_lessons_count += 1
                    else:
                         logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] No result or error returned for lesson {lesson_id}")

                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] All lesson results processed. {processed_lessons_count} lessons processed successfully.")
                # ----- End Synchronous DB Updates ----- #

            except Exception as e:
                logger.exception(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Error during execution for course {course_id}: {e}")
            finally:
                logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Entering finally block.")
                if course and session.is_active:
                    logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Setting is_working=False for course {course_id}.")
                    try:
                        course_in_session = session.get(Course, course_id)
                        if course_in_session:
                            course_in_session.is_working = False
                            session.add(course_in_session)
                            session.commit()
                            logger.info(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Committed is_working=False.")
                        else:
                            logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Course {course_id} not found in session during finally block.")
                    except Exception as finally_e:
                        logger.error(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Error setting is_working=False in finally block: {finally_e}")
                        session.rollback()
                elif not course:
                     logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Course object was None in finally block, cannot set is_working=False.")
                elif not session.is_active:
                     logger.warning(f"[BACKGROUND][_actual_lessons_plan_task][{course_id}] Session inactive in finally block, cannot set is_working=False.")

    try:
        logger.info(f"[BACKGROUND][run_lessons_plan_task][{course_id}] Running async core logic using asyncio.run().")
        asyncio.run(_actual_lessons_plan_task())
        logger.info(f"[BACKGROUND][run_lessons_plan_task][{course_id}] Async core logic finished.")
    except Exception as e:
        logger.error(f"[BACKGROUND][run_lessons_plan_task][{course_id}] Top-level error running task for {course_id}: {e}", exc_info=True)
    finally:
        logger.info(f"[BACKGROUND][run_lessons_plan_task][{course_id}] Background task execution finished for course {course_id}.")

def run_write_lessons_task(course_id: int):
    """Background task wrapper to write content for all lessons in a course asynchronously."""
    logger.info(f"[BACKGROUND][run_write_lessons_task][{course_id}] Starting write lessons task for course ID: {course_id}")

    async def _actual_write_lessons_task():
        """Asynchronous core logic for writing lesson content."""
        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Entering async core logic.")
        course_with_lessons = None
        processed_content_count = 0
        with Session(engine) as session:
            try:
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Fetching course and lesson data.")
                course_with_lessons = session.exec(
                    select(Course).where(Course.id == course_id).options(selectinload(Course.lessons).selectinload(Lesson.sections))
                ).first()

                if not course_with_lessons:
                     logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Course {course_id} not found after loading.")
                     return
                if not course_with_lessons.lessons:
                     logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] No lessons found for course {course_id} after loading.")
                     return

                course_with_lessons.is_working = True
                session.add(course_with_lessons)
                session.commit()
                session.refresh(course_with_lessons)
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Set is_working=True for course {course_id}.")

                language = course_with_lessons.language
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Preparing lessons for writing.")

                valid_lessons_data = []
                valid_lesson_ids = []

                for lesson in course_with_lessons.lessons:
                    if lesson.sections and len(lesson.sections) > 0:
                        try:
                            structured_plan = lesson.get_structured_plan() # Sync call
                            search_query = structured_plan.general_plan + "\n" + "\n".join(sec.instructions for sec in structured_plan.sections)
                            relevant_content = course_with_lessons.get_relevant_content(search_query)
                            valid_lessons_data.append((lesson.id, structured_plan, relevant_content))
                            valid_lesson_ids.append(lesson.id)
                        except Exception as plan_err:
                             logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Error preparing lesson {lesson.id} for writing: {plan_err}")

                if not valid_lessons_data:
                    logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] No valid lessons data prepared. Nothing to write.")
                    return

                total_valid_lessons = len(valid_lessons_data)
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Prepared {total_valid_lessons} lessons for async writing in course {course_id}")

                # ----- Start Asynchronous AI Calls (Write + Improve per lesson) ----- #
                async def process_single_lesson(lesson_id, structured_plan, relevant_content_initial, course_obj):
                    """Handles the write -> improve flow for one lesson."""
                    try:
                        lesson_generation = await write_lesson(structured_plan, language, relevant_content_initial)
                        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Lesson {lesson_id} written. Starting improvement.")
                        all_content = "\n".join(content for content in lesson_generation.content_for_section)
                        relevant_content_for_improve = course_obj.get_relevant_content(all_content)
                        improved_generation = await improve_lesson(lesson_generation, language, relevant_content_for_improve)
                        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Lesson {lesson_id} improved. Returning.")
                        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Improved generation DONE")
                        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Improved generation DONE SAFE")
                        return lesson_id, improved_generation
                    except Exception as e:
                        logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Error processing lesson {lesson_id} async: {e}")
                        return lesson_id, e

                ai_tasks = []
                for lesson_id, structured_plan, relevant_content in valid_lessons_data:
                    ai_tasks.append(process_single_lesson(lesson_id, structured_plan, relevant_content, course_with_lessons))

                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Gathering {len(ai_tasks)} write/improve tasks for course {course_id}.")

                lesson_results = await asyncio.gather(*ai_tasks)
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Finished gathering write/improve results for course {course_id}.")
                # ----- End Asynchronous AI Calls ----- #

                # ----- Start Synchronous DB Updates ----- #
                lessons_with_content = 0
                lessons_to_update = session.exec(select(Lesson).where(Lesson.id.in_(valid_lesson_ids)).options(selectinload(Lesson.sections))).all()
                lesson_map = {lesson.id: lesson for lesson in lessons_to_update}

                for result in lesson_results:
                    lesson_id, generation_or_error = result
                    lesson = lesson_map.get(lesson_id)

                    if not lesson:
                        logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Lesson {lesson_id} not found in map after async processing.")
                        continue

                    if isinstance(generation_or_error, Exception):
                        logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Failed to process lesson {lesson_id}: {generation_or_error}")
                        continue
                    elif generation_or_error:
                        improved_generation = generation_or_error
                        logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Updating sections for lesson {lesson.id}")
                        sections_list = sorted(lesson.sections, key=lambda s: s.id)
                        if len(sections_list) != len(improved_generation.title_for_section):
                            logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Mismatch section count for lesson {lesson.id}. DB: {len(sections_list)}, AI: {len(improved_generation.title_for_section)}. Skipping update.")
                            continue
                        else:
                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Saving content for {len(sections_list)} sections in lesson {lesson_id}.")
                            
                            current_lesson_section_ids_having_content = []

                            for section, title, content in zip(sections_list, improved_generation.title_for_section, improved_generation.content_for_section):
                                section.title = title
                                section.content = content
                                if section.content and isinstance(section.content, str) and section.content.strip():
                                    current_lesson_section_ids_having_content.append(section.id)

                            # 2. Prepare and Gather Quiz Tasks for this Lesson
                            quiz_tasks = []
                            section_quiz_map = {}
                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Preparing quiz tasks for {len(sections_list)} sections in lesson {lesson_id}.")
                            for section in sections_list:
                                if section.content:
                                    task = create_quiz(section.content, language)
                                    quiz_tasks.append(task)
                                    section_quiz_map[task] = section
                                else:
                                     logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Skipping quiz for section {section.id} due to missing content.")

                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Gathering {len(quiz_tasks)} quiz results for lesson {lesson_id}.")
                            quiz_results = await asyncio.gather(*quiz_tasks, return_exceptions=True)
                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Finished gathering quiz results for lesson {lesson_id}.")

                            # 3. Process Quiz Results and Update DB
                            for task, quiz_model_or_error in zip(quiz_tasks, quiz_results):
                                section = section_quiz_map.get(task)
                                if not section:
                                    logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Could not map quiz task result back to section in lesson {lesson_id}. Skipping.")
                                    continue

                                if isinstance(quiz_model_or_error, Exception):
                                    logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Quiz generation failed for section {section.id}: {quiz_model_or_error}")
                                elif quiz_model_or_error:
                                    quiz_model = quiz_model_or_error
                                    if section.quiz:
                                        session.delete(section.quiz)
                                    new_quiz = Quiz(
                                        title=quiz_model.title,
                                        question=quiz_model.question,
                                        correct_answer=quiz_model.correct_answer,
                                        incorrect_answer_1=quiz_model.incorrect_answer_1,
                                        incorrect_answer_2=quiz_model.incorrect_answer_2,
                                        incorrect_answer_3=quiz_model.incorrect_answer_3,
                                        section=section,
                                    )
                                    session.add(new_quiz)
                                    section.quiz = new_quiz
                                    logger.debug(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Successfully generated quiz for section {section.id}.")
                                else:
                                    logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Quiz generation returned None for section {section.id}.")

                            # Commit content and quiz updates together for the lesson
                            session.commit()
                            processed_content_count += 1 # Increment count after successful lesson processing (content + quizzes)
                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Committed content and quizzes for lesson {lesson_id}.")
                    else:
                        logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] No result or error returned for lesson {lesson_id}")

                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Write task completed. {processed_content_count} lessons updated.")
                # ----- End Synchronous DB Updates ----- #

            except Exception as e:
                logger.exception(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Error in write lessons task: {e}")
            finally:
                logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Entering finally block.")
                if course_with_lessons and session.is_active:
                    logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Setting is_working=False for course {course_id}.")
                    try:
                        course_in_session = session.get(Course, course_id)
                        if course_in_session:
                            course_in_session.is_working = False
                            session.add(course_in_session)
                            session.commit()
                            logger.info(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Committed is_working=False.")
                        else:
                            logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Course {course_id} not found in session during finally block.")
                    except Exception as finally_e:
                        logger.error(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Error setting is_working=False in finally block: {finally_e}")
                        session.rollback()
                elif not course_with_lessons:
                    logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Course object was None in finally block, cannot set is_working=False.")
                elif not session.is_active:
                    logger.warning(f"[BACKGROUND][_actual_write_lessons_task][{course_id}] Session inactive in finally block, cannot set is_working=False.")

    try:
        logger.info(f"[BACKGROUND][run_write_lessons_task][{course_id}] Running async core logic.")
        asyncio.run(_actual_write_lessons_task())
        logger.info(f"[BACKGROUND][run_write_lessons_task][{course_id}] Async core logic finished.")
    except Exception as e:
        logger.error(f"[BACKGROUND][run_write_lessons_task][{course_id}] Top-level error running write lessons task for {course_id}: {e}")
    finally:
        logger.info(f"[BACKGROUND][run_write_lessons_task][{course_id}] Background task execution finished for course {course_id}.")

def run_full_course_generation_task(course_id: int, request_data: dict):
    """Background task wrapper for the full course generation pipeline."""
    logger.info(f"[BACKGROUND][run_full_course_generation_task][{course_id}] Starting for course ID: {course_id}")
    request_prompt = request_data.get("prompt")
    request_language = request_data.get("language")
    request_duration_minutes = request_data.get("duration_minutes")
    request_ai_images = request_data.get("ai_images", False)

    async def _actual_full_course_generation_task():
        """Asynchronous core logic for the full generation pipeline."""
        logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Entering async core logic.")
        course = None
        with Session(engine) as session:
            language = request_language
            lessons_with_plans = []
            sections_with_content = []
            total_slides_generated = 0

            try:
                # --- Initial Setup --- Fetch course and set is_working --- 
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Fetching course data.")
                course: Course = session.exec(
                    select(Course).where(Course.id == course_id).options(selectinload(Course.documents).selectinload(Document.chunks))
                ).first()

                if not course:
                    logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Course {course_id} not found.")
                    return

                course.is_working = True
                session.add(course)
                session.commit()
                session.refresh(course)
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Set is_working=True for course {course_id}.")

                language = course.language or request_language

                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Starting full generation pipeline.")

                # --- Step 0: Delete Existing Lessons/Slides --- 
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 0: Deleting existing lessons for course {course_id}.")
                existing_lessons = session.exec(select(Lesson).where(Lesson.course_id == course_id)).all()
                if existing_lessons:
                    for lesson in existing_lessons:
                        session.delete(lesson)
                    session.commit()
                    session.refresh(course)
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Finished deleting existing lessons.")
                else:
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No existing lessons to delete.")


                # --- Step 1: Generate Time Structure ---
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 1: Generating time structure.")
                time_structure = await generate_time_structure(request_prompt, request_duration_minutes, retry=3)
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Time structure generated: {time_structure.number_of_lessons} lessons.")
                course.number_of_lessons = time_structure.number_of_lessons
                course.time_structure = json.dumps(time_structure.model_dump())
                course.duration_minutes = time_structure.duration_minutes
                course.ai_images = request_ai_images
                session.add(course)
                session.commit()
                session.refresh(course)

                # --- Step 2: Generate Course Plan ---
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 2: Generating course plan.")
                relevant_content_plan = course.get_relevant_content(request_prompt) # Sync
                course_plan = await genererate_course_plan(request_prompt, language, time_structure, relevant_content_plan)
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Course plan generated. Title: {course_plan.title_for_course}")
                course.title = course_plan.title_for_course
                course.preset = course_plan.slide_preset
                course.background = "light"
                course.ai_images = request_ai_images
                session.add(course)
                session.commit()
                session.refresh(course)

                # --- Step 3: Create Lesson DB Objects ---
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 3: Creating {time_structure.number_of_lessons} Lesson DB objects.")
                lesson_db_objects = []
                lesson_data_for_plan = []
                num_lessons_to_create = time_structure.number_of_lessons

                for i in range(num_lessons_to_create):
                    lesson_prompt = course_plan.prompt_for_lesson[i]
                    lesson_title = course_plan.title_for_lesson[i]
                    lesson_time_structure = time_structure.lessons[i]
                    lesson = Lesson(
                        title=lesson_title,
                        prompt=lesson_prompt,
                        course_id=course.id,
                        time_structure=json.dumps(lesson_time_structure.model_dump()),
                        duration_minutes=lesson_time_structure.duration_minutes
                    )
                    session.add(lesson)
                    lesson_db_objects.append(lesson)

                session.commit()
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Committed {len(lesson_db_objects)} new lessons.")
                for lesson in lesson_db_objects:
                     session.refresh(lesson)
                     rel_content = course.get_relevant_content(lesson.prompt)
                     lesson_data_for_plan.append((lesson.id, lesson.prompt, LessonTimeStructure.model_validate(json.loads(lesson.time_structure)), rel_content))

                # --- Step 4: Generate Lesson Plans (Parallel) ---
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 4: Generating detailed plans for {len(lesson_data_for_plan)} lessons in parallel.")

                plan_tasks = []
                for lesson_id, prompt, time_struct, rel_content in lesson_data_for_plan:
                    plan_tasks.append(get_lesson_plan_with_retry(prompt, language, time_struct, rel_content))

                lesson_plan_results = await asyncio.gather(*plan_tasks, return_exceptions=True)
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Gathered {len(lesson_plan_results)} lesson plan results.")

                lesson_map_for_update = {lesson.id: lesson for lesson in lesson_db_objects}
                processed_plans_count = 0
                failed_plans_count = 0
                for i, result in enumerate(lesson_plan_results):
                    lesson_id, _, _, _ = lesson_data_for_plan[i]
                    lesson_obj = lesson_map_for_update.get(lesson_id)
                    if not lesson_obj:
                        logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Lesson object {lesson_id} not found in map after planning.")
                        failed_plans_count += 1
                        continue

                    if isinstance(result, Exception):
                        logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Failed to generate plan for lesson {lesson_id}: {result}")
                        failed_plans_count += 1
                    elif result:
                        structured_plan = result
                        lessons_with_plans.append((lesson_id, structured_plan))
                        processed_plans_count += 1
                        logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Saving plan for lesson {lesson_id} with {len(structured_plan.sections)} sections.")
                        lesson_obj.general_plan = structured_plan.general_plan
                        session.add(lesson_obj)
                        for section_plan in structured_plan.sections:
                            section = Section(
                                short_description=section_plan.short_description,
                                instructions=section_plan.instructions,
                                style=section_plan.style,
                                duration_minutes=section_plan.duration_minutes,
                                lesson_id=lesson_id
                            )
                            session.add(section)
                        session.commit()
                    else:
                         logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No plan generated for lesson {lesson_id}")
                         failed_plans_count += 1

                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Finished processing lesson plans. Success: {processed_plans_count}, Failed: {failed_plans_count}")

                # --- Step 5: Write and Improve Lesson Content (Parallel) ---
                if not lessons_with_plans:
                    logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No successful lesson plans generated. Skipping content writing.")
                else:
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 5: Writing and improving content for {len(lessons_with_plans)} lessons in parallel.")

                    async def process_lesson_content(lesson_id, structured_plan, lang, course_obj):
                        """Handles write -> improve flow for one lesson. Needs course object for context."""
                        try:
                            logger.debug(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Writing content for lesson {lesson_id}")
                            rel_content_write = course_obj.get_relevant_content(structured_plan.general_plan)
                            lesson_generation = await write_lesson(structured_plan, lang, rel_content_write)
                            logger.debug(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Improving content for lesson {lesson_id}")
                            all_written_content = "\n".join(lesson_generation.content_for_section)
                            rel_content_improve = course_obj.get_relevant_content(all_written_content)
                            improved_generation = await improve_lesson(lesson_generation, lang, rel_content_improve)
                            return lesson_id, improved_generation
                        except Exception as e:
                            logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Error processing content for lesson {lesson_id}: {e}")
                            return lesson_id, e

                    content_tasks = []
                    for lesson_id, structured_plan in lessons_with_plans:
                        content_tasks.append(process_lesson_content(lesson_id, structured_plan, language, course))

                    lesson_content_results = await asyncio.gather(*content_tasks)
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Gathered {len(lesson_content_results)} lesson content results.")

                    processed_content_count = 0
                    failed_content_count = 0
                    sections_to_update = session.exec(
                        select(Section).where(Section.lesson_id.in_([lid for lid, _ in lessons_with_plans])).order_by(Section.lesson_id, Section.id)
                    ).all()
                    section_map = {}
                    for sec in sections_to_update:
                        if sec.lesson_id not in section_map:
                            section_map[sec.lesson_id] = []
                        section_map[sec.lesson_id].append(sec)

                    for i, result in enumerate(lesson_content_results):
                        lesson_id, generation_or_error = result
                        sections_list = section_map.get(lesson_id)

                        if not sections_list:
                             logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No sections found in map for lesson {lesson_id} during content update.")
                             failed_content_count += 1
                             continue

                        if isinstance(generation_or_error, Exception):
                             logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Failed to generate/improve content for lesson {lesson_id}: {generation_or_error}")
                             failed_content_count += 1
                        elif generation_or_error:
                            improved_generation = generation_or_error
                            if len(sections_list) != len(improved_generation.title_for_section):
                                logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Lesson {lesson_id}: Section count mismatch during content update. DB={len(sections_list)}, AI={len(improved_generation.title_for_section)}. Skipping update.")
                                failed_content_count += 1
                            else:
                                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Saving content for {len(sections_list)} sections in lesson {lesson_id}.")
                                
                                current_lesson_section_ids_having_content = []

                                for section, title, content in zip(sections_list, improved_generation.title_for_section, improved_generation.content_for_section):
                                    section.title = title
                                    section.content = content
                                    if section.content and isinstance(section.content, str) and section.content.strip():
                                        current_lesson_section_ids_having_content.append(section.id)

                                    # 2. Prepare and Gather Quiz Tasks for this Lesson
                                    quiz_tasks = []
                                    section_quiz_map = {}
                                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Preparing quiz tasks for {len(sections_list)} sections in lesson {lesson_id}.")
                                    for section in sections_list:
                                        if section.content:
                                            task = create_quiz(section.content, language)
                                            quiz_tasks.append(task)
                                            section_quiz_map[task] = section
                                        else:
                                             logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Skipping quiz for section {section.id} due to missing content.")

                                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Gathering {len(quiz_tasks)} quiz results for lesson {lesson_id}.")
                                    quiz_results = await asyncio.gather(*quiz_tasks, return_exceptions=True)
                                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Finished gathering quiz results for lesson {lesson_id}.")

                                    # 3. Process Quiz Results and Update DB
                                    for task, quiz_model_or_error in zip(quiz_tasks, quiz_results):
                                        section = section_quiz_map.get(task)
                                        if not section:
                                            logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Could not map quiz task result back to section in lesson {lesson_id}. Skipping.")
                                            continue

                                        if isinstance(quiz_model_or_error, Exception):
                                            logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Quiz generation failed for section {section.id}: {quiz_model_or_error}")
                                        elif quiz_model_or_error:
                                            quiz_model = quiz_model_or_error
                                            if section.quiz:
                                                session.delete(section.quiz)
                                            new_quiz = Quiz(
                                                title=quiz_model.title,
                                                question=quiz_model.question,
                                                correct_answer=quiz_model.correct_answer,
                                                incorrect_answer_1=quiz_model.incorrect_answer_1,
                                                incorrect_answer_2=quiz_model.incorrect_answer_2,
                                                incorrect_answer_3=quiz_model.incorrect_answer_3,
                                                section=section,
                                            )
                                            session.add(new_quiz)
                                            section.quiz = new_quiz
                                            logger.debug(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Successfully generated quiz for section {section.id}.")
                                        else:
                                            logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Quiz generation returned None for section {section.id}.")

                                    # Commit content and quiz updates together for the lesson
                                    session.commit()
                                    sections_with_content.extend(current_lesson_section_ids_having_content)
                                    processed_content_count += 1 # Increment count after successful lesson processing (content + quizzes)
                                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Committed content and quizzes for lesson {lesson_id}.")
                        else:
                            logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No content result for lesson {lesson_id}")
                            failed_content_count += 1

                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Finished processing lesson content. Success: {processed_content_count}, Failed: {failed_content_count}")

                # --- Step 6: Generate Slides (Parallel) ---
                if not sections_with_content:
                     logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No sections found with content. Skipping slide generation.")
                     total_slides_generated = 0
                else:
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Step 6: Generating slides for {len(sections_with_content)} sections in parallel.")

                    sections_for_slides = session.exec(
                        select(Section).where(Section.id.in_(sections_with_content))
                    ).all()

                    # NEW SLIDE MARKDOWN GENERATION WORKFLOW ---------------------------------
                    slide_gen_tasks: list[asyncio.Future] = []
                    section_id_map_slides: dict[asyncio.Future, int] = {}

                    # Remove any existing slide markdown for these sections first
                    if sections_with_content:
                        delete_stmt = delete(Slide).where(Slide.section_id.in_(sections_with_content))
                        session.exec(delete_stmt)
                        session.commit()

                    for section in sections_for_slides:
                        if section.content and section.title:
                            full_section_content = f"# {section.title}\n\n{section.content}"
                            task_future = write_presentation_markdown(full_section_content, language=language, ai_images=request_ai_images)
                            slide_gen_tasks.append(task_future)
                            section_id_map_slides[task_future] = section.id
                        else:
                            logger.warning(
                                f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Section {section.id} targeted for slides missing title/content on refetch."
                            )

                    if not slide_gen_tasks:
                        logger.warning(
                            f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No valid sections left for slide markdown generation after fetching."
                        )
                    else:
                        logger.info(
                            f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Gathering {len(slide_gen_tasks)} slide markdown generation tasks."
                        )

                        markdown_results = await asyncio.gather(*slide_gen_tasks, return_exceptions=True)
                        logger.info(
                            f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Finished gathering slide markdown generation results."
                        )

                        processed_sections_count = 0
                        failed_sections_count = 0

                        for idx, result in enumerate(markdown_results):
                            task_future = slide_gen_tasks[idx]
                            section_id = section_id_map_slides.get(task_future)

                            if section_id is None:
                                logger.error(
                                    f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Could not map markdown result index {idx} back to a section ID."
                                )
                                failed_sections_count += 1
                                continue

                            if isinstance(result, Exception):
                                logger.error(
                                    f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Failed to generate slide markdown for section {section_id}: {result}"
                                )
                                failed_sections_count += 1
                            elif result:
                                # If AI images were requested, replace placeholders by generating the images now
                                try:
                                    markdown_final = result
                                    if request_ai_images:
                                        markdown_final = await generate_ai_images_for_markdown(markdown_final)

                                    # Attempt to fix Pandoc compile errors
                                    markdown_final = await improve_slides(markdown_final)
                                except Exception as img_err:
                                    logger.error(
                                        f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Error generating images for section {section_id}: {img_err}"
                                    )
                                    markdown_final = result  # fallback to original

                                processed_sections_count += 1
                                new_slide = Slide(section_id=section_id, markdown_content=markdown_final)
                                session.add(new_slide)
                            else:
                                logger.warning(
                                    f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] No markdown generated for section {section_id}."
                                )
                                failed_sections_count += 1

                        if processed_sections_count:
                            session.commit()
                            logger.info(
                                f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Saved slide markdown for {processed_sections_count} sections."
                            )
                        logger.info(
                            f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Slide markdown generation completed. Success: {processed_sections_count}, Failed: {failed_sections_count}."
                        )

                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Full generation pipeline completed for course ID: {course_id}.")

            except Exception as e:
                logger.exception(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Error during full generation for course {course_id}: {e}")
            finally:
                logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Entering finally block.")
                if course and session.is_active:
                    logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Setting is_working=False for course {course_id}.")
                    try:
                        course_in_session = session.get(Course, course_id)
                        if course_in_session:
                            course_in_session.is_working = False
                            session.add(course_in_session)
                            session.commit()
                            logger.info(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Committed is_working=False.")
                        else:
                            logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Course {course_id} not found in session during finally block.")
                    except Exception as finally_e:
                         logger.error(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Error setting is_working=False in finally block: {finally_e}")
                         session.rollback()
                elif not course:
                     logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Course object was None in finally block, cannot set is_working=False.")
                elif not session.is_active:
                     logger.warning(f"[BACKGROUND][_actual_full_course_generation_task][{course_id}] Session inactive in finally block, cannot set is_working=False.")


    try:
        logger.info(f"[BACKGROUND][run_full_course_generation_task][{course_id}] Running async core logic.")
        asyncio.run(_actual_full_course_generation_task())
        logger.info(f"[BACKGROUND][run_full_course_generation_task][{course_id}] Async core logic finished.")
    except Exception as e:
        logger.error(f"[BACKGROUND][run_full_course_generation_task][{course_id}] Top-level error running task for {course_id}: {e}", exc_info=True)
    finally:
        logger.info(f"[BACKGROUND][run_full_course_generation_task][{course_id}] Background task execution finished for course {course_id}.")


